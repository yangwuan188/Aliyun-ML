# 朴素贝叶斯

### 1 朴素贝叶斯介绍

朴素贝叶斯分类方法是基于贝叶斯定理和特征条件独立假设的一种分类器。
Naive Bayes模型所需估计的参数很少，对缺失数据不太敏感，算法也比较简单。

贝叶斯定理： 
$$
p(A|B)=\frac{p(A,B)}{p(B)}=\frac{p(B|A) \cdot p(A)}{\sum_{a \in ℱ_A}p(B|a) \cdot p(a)}
$$
其中：
p(A,B)：表示事件A和事件B同时发生的概率。

p(B)：表示事件B发生的概率，叫做先验概率；p(A)：表示事件A发生的概率。

p(A|B)：表示当事件B发生的条件下，事件A发生的概率叫做后验概率。

p(B|A)：表示当事件A发生的条件下，事件B发生的概率。

 贝叶斯分类器是一种源于贝叶斯定理的最大后验估计（MAP）：
 
 $$
 p(C_i|X)=\frac{p(X|C_i)p(C_i)}{p(X)}
 $$
其中P(X)可以忽略，因为对于每一个类，P(X)都是一样的。我们只需要计算先验 $p(C_i)$ 和条件概率 $p(X|C_i)$ 来得出最大后验。

### 2 判别模型和生成模型

![discriminative_generative](DisandGen.png)

机器学习的目标是根据特征X来预测标签Y，即求 P(Y|X).
判别模型根据 P(Y|X)直接求得标签y，其实是直接得到判别边界，如回归模型，SVM都属于判别模型。
生成模型要先求得P(Y,X)，对于预测数据X，要分别计算X和不同标签Y1,Y2,Y3....的联合概率分布，和哪个类别的联合概率大即属于哪类。如朴素贝叶斯，HMM属于生成模型。
